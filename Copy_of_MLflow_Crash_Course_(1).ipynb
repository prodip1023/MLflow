{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> ğŸ‘‹  Welcome to the MLFlow Crash Course</h1>\n",
        "\n",
        "<h1>Part 1</h1></center>\n",
        "\n",
        "---\n",
        "\n",
        "With 243M downloads and 13K stars on GitHub - MLflow is one of the most widely adopted open-source tools for machine learning lifecycle management. It supports live logging of parameters, metrics, and artifacts, in addition to providing a Model Registry with Deployment functionality.\n",
        "\n",
        "We integrated MLflow into DagsHub almost two years ago, providing a zero-configuration remote MLflow Server with built-in access controls, that support MLflow's Tracking, Model Registry, and Deployment functionality. We've dived into its internals, handled many of its specifics, and now we want to share the knowledge we gained with the data science community!\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "<h4>\n",
        " In the session today, we will use DagsHub integration with MLflow. â¤ï¸\n",
        "\n",
        " You will log experiment to a remote server by running only 3 simple commands!\n",
        "\n",
        " For that, you will need to sign up for DagsHub (for free) ğŸ‘‡\n",
        "</h4>\n",
        "<center><h3><a href=\"https://bit.ly/3Sjl9UA\">Sign up to DagsHub</a></h3></center>\n",
        "\n",
        "<center><img src=\"https://res-2.cloudinary.com/crunchbase-production/image/upload/c_lpad,f_auto,q_auto:eco/plwmuai9t3okgwbuhkho\" height=\"100\"/></center>\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "\n",
        "<img src=\"https://dragonballz.co.il/wp-content/uploads/2020/12/discord-logo.jpg\" height=\"23\"/> [Discord Channel](https://discord.com/channels/698874030052212737/698874030572437526) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Linkedin.svg/1200px-Linkedin.svg.png\" height=\"23\"/> [LinkedIn](https://www.linkedin.com/company/dagshub/) | <img src=\"https://help.twitter.com/content/dam/help-twitter/brand/logo.png\" height=\"25\"/> [Twitter](https://twitter.com/TheRealDAGsHub) | <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Octicons-mark-github.svg/1200px-Octicons-mark-github.svg.png\" height=\"25\"/> [GitHub](https://github.com/DAGsHub) | <img src=\"\thttps://www.mlflow.org/docs/latest/_static/MLflow-logo-final-black.png\" height=\"30\"/> [MLFlow](https://www.mlflow.org/)\n",
        "\n"
      ],
      "metadata": {
        "id": "iWUkRt7z2hkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# â“ What are we learning today?"
      ],
      "metadata": {
        "id": "i5AX2fpblSyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Why do we need MLflow?\n",
        "- What is MLflow?\n",
        "- MLflow Tracking Functionality\n",
        "  - Understanding Runs & Experiments\n",
        "  - Logging Runs & Experiments\n",
        "  - How and where are the runs recorded?\n",
        "- Hands-on Experience using MLflow"
      ],
      "metadata": {
        "id": "lG6_hUNcE4qy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ğŸ¤Œ Why do we need MLFlow?\n",
        "\n",
        "**<h3> Do we really spend 80% of our time only cleaning data?</h3>**\n",
        "\n",
        "\n",
        "<p float=\"left\">\n",
        "  <img src=\"https://drive.google.com/uc?id=1ZMVUUsVDRaGRD_aIa8E-4lkGFxxo1WGB\" height=\"200\" />\n",
        "  <img src=\"https://drive.google.com/uc?id=1tK9igz88eMHV115R_0jDuzuPBY9GSTRQ\" height=\"220\" />\n",
        "  <img src=\"https://drive.google.com/uc?id=11QSKrW29sWfD2lPse_hXpYD9Ql6tLQjo\" height=\"200\" />\n",
        "</p>"
      ],
      "metadata": {
        "id": "w5e-om3x4qeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**<h3>ğŸ’¡The effort and time spent in logging the experiments is always underestimated</h3>**\n",
        "\n",
        "Do you find yourself doing CTRL-Y / â‡§âŒ˜Z multiple times to find that perfect code which gave you an awesome accuracy or confidence score before you messed it up with the new experiment you decided to run? Or the optimal set of hyper parameters that you used for that run?\n",
        "\n",
        "**<h3>â“Another question that arises is of reproducibility of your experiments.</h3>**\n",
        "\n",
        "This is how I was trying to structure my experiments using a Notion Table to keep track of them :\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1xD1aR3-yZICt9vMIdIHkATBMBAS6Pcbx\" height=\"\"/>\n",
        "</center>\n",
        "\n",
        "\n",
        "While Notion is a great tool for note keeping, we canâ€™t say the same when it comes to tracking the machine learning experimentation and workflow.\n",
        "\n",
        "**<h3>In the midst of all this hardship, I discovered MLflow, my savior!</h3>**"
      ],
      "metadata": {
        "id": "dtInWfJ_zZ0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âš¡ What is MLFlow?"
      ],
      "metadata": {
        "id": "IyObzxJLjGJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "MLflow is an **open-source tool** to manage the machine learning lifecycle. It supports **live logging** of parameters, metrics, metadata, and artifacts when running a machine learning experiment. To manage the post-training stage, it provides a **model registry** with **deployment functionality** to custom serving tools.\n",
        "\n",
        "It was created to :\n",
        "- Reduce the complexity in monitoring the experiments.\n",
        "- Ease the reproducibility of theÂ results.\n",
        "- Cater the need of a standardized mechanism to register and deploy models to production.\n",
        "\n",
        "**<h3> ğŸ‚ Introduced in June 2018 by Databricks to offer </h3>**\n",
        "- **Open interface** : Any ML library, algorithm, cloud provider, or language may be used with MLflow.\n",
        "- **Open source** :Â MLflow is anÂ open source projectÂ that users and library developers can extend.\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1m0uXc3gZff1prgl_-DRfmg5whRwWboFJ\" height=\"\"/>\n",
        "</center>\n",
        "\n",
        "Reference blog to the stats - Click [here](https://www.databricks.com/blog/2018/06/05/introducing-mlflow-an-open-source-machine-learning-platform.html)!"
      ],
      "metadata": {
        "id": "WIU_pHsS5LDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§© The MLFlow Components:\n",
        "\n",
        "**Components that MLFlow offers to help you manage your workflow :**\n",
        "- **MLflow Tracking -** Log parameters, metrics, and artifacts when running a machine learning code.\n",
        "- **MLflow Projects**Â - Package and reuse data science code.\n",
        "- **MLflow Registry -** Manage the lifespan of ML Model.\n",
        "- **MLflow Models**Â - Package and deploy ML models.\n"
      ],
      "metadata": {
        "id": "HHfth5VnAYr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Today we will be talking about tracking our ML experiments using MLflow. </h3>\n",
        "\n",
        "OnÂ SeptemberÂ 27th,Â inÂ theÂ [secondÂ partÂ ofÂ ourÂ CrashÂ Course](https://www.linkedin.com/events/mlflowcrashcourse-part26975758317688111104/comments/), YonoÂ willÂ explore:\n",
        "\n",
        "1. **Model Registry** - Log and manage your machine learning models with MLflow.\n",
        "2. **Model Deployment** - Deploy your trained model from the MLflow registry to AWS.\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1ajZSBD1LzOyNn3uIFL5l422JmDBiZmBC\" height=\"\"/></center>\n"
      ],
      "metadata": {
        "id": "TwVcMqEEBsgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥MLflow Tracking Functionality\n"
      ],
      "metadata": {
        "id": "Ft1TaiLVCIzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸƒâ€â™‚ï¸& ğŸ§ª Understanding Runs & Experiments\n",
        "\n",
        "- The **experiment** unit in MLflow can be handled as a \"project\" or as a \"approach\".  \n",
        "- The term **run** merely refers to a run or execution of a code once.\n",
        "\n",
        "*More than one run might be associated with a single experiment.*\n",
        "\n",
        "Each run is an execution of your data science code which records the following:\n",
        "\n",
        "- **Source of execution**: Contains the hash of the commit if the code was pushed to GitHub and the original line of code that was utilized for the run.\n",
        "- **Artifacts**: Artifacts are output files recorded during a run.\n",
        "- **Parameters**: Parameters are stored in the key-value format.\n",
        "- **Metrics:** The evaluation metrics such as RMSE or ROC-AUC are recorded in a run as well."
      ],
      "metadata": {
        "id": "DSePjmf5F8Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœï¸ How and where are the runs recorded?\n"
      ],
      "metadata": {
        "id": "uNOfQVFOju3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Runs of MLflow can be stored locally in files, remotely on a tracking server, or in a database that is compatible with [SQLAlchemy](https://www.sqlalchemy.org/) - an open-source SQL toolkit and object-relational mapper for the Python programming language.*\n",
        "\n",
        "### Scenario 1: MLflow on localhost\n",
        "- A good first-time technique to get started.\n",
        "- MLflow will create a directory called **./mlruns** on your local system as soon as you import MLflow and log an artifact.\n",
        "- Limitations on collaboration because experiments or results can't be shared with a team.\n",
        "- Tracking UI - To visualize, search and compare runs, as well as download run artifacts or metadata for analysis in other tools by running the command `mlflow ui`.\n",
        "<center> <img src=\"https://drive.google.com/uc?id=182URyB-0ezmZCkQg-TKVrt-OmYbiyECM\" height=\"150%\"/>\n",
        "</center>\n",
        "\n",
        "The UI contains the following key features:\n",
        "\n",
        "- Experiment-based run listing and comparison (including run comparison across multiple experiments)\n",
        "- Searching for runs by parameter or metric value\n",
        "- Visualizing run metrics\n",
        "- Downloading run results"
      ],
      "metadata": {
        "id": "LZrJPCBjCIvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 2: MLflow on localhost with SQLite\n",
        "\n",
        "The only difference between this process and the previous one is that we use a local database such as SQLite instead of storing runs to files."
      ],
      "metadata": {
        "id": "jhgxn4RSj4kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\\\n",
        "\n",
        "### Scenario 3: MLflow on localhost with Tracking Server\n",
        "\n",
        "This scenario is again similar to the first scenario but here, you can setup a remote server using `mlflow server <args>` which will launch the tracking server at the default port 5000.\n",
        "\n"
      ],
      "metadata": {
        "id": "1IoeEu-Mj4bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 4: MLflow with remote Tracking Server, backend and artifact stores\n",
        "- The tracking server, backend store, and artifact store may all be located on different hosts in distributed architectures.\n",
        "- The MLflow client communicates with the tracking server through a sequence of REST requests in order to record all runs' MLflow entities.\n",
        "- The MLflow client interacts with the remote Tracking Server and artifact storage host such as AWS using theÂ boto clientÂ libraries, and uploads the artifacts to the S3 bucket URI location.\n",
        "- This set up requires DevOps knowledge.\n",
        "\n",
        "\\\\\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1iqhhqw7yT4GjUlpV6IoYLLuy1BeVtDA0\" height=\"120%\"/>\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "DO6gTnOrj4X2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 5: MLflow Tracking Server enabled with proxied artifact storage access\n",
        "\n",
        "\\\\\n",
        "\n",
        "*In this case, it is not necessary to grant end users direct path access to a remote object store (such as S3, ADL, GCS, or HDFS) for the management of artifact, nor is it necessary for an end user to provide access credentials.*\n",
        "\n",
        "\\\\\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=17ERqAUwx7OUcph3EjPUPL4OoyCwuhh2W\" height=\"120%\"/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "pC2FkQoOj4V-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scenario 6: MLflow x DagsHub\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1kDoJcbYj_mebQ-6Dh6aPe-OE5LNSvqsR\" height=\"80%\"/>\n",
        "</center>\n",
        "\n",
        "- Going through all the above can be a bit of an hassle, even for people with DevOps background. To simplify the process, DagsHub decided to do the MLOps heavy lifting for you.\n",
        "\n",
        "- **DagsHub provides a free remote MLflow server with every repository.**\n",
        "\n",
        "- You can log experiments with MLflow to it, view its information under theÂ [experiment tab](https://dagshub.com/docs/feature_guide/discovering_experiments/), and manage your trained models from the full-fledged MLflow UI built into your DagsHub project.\n",
        "\n",
        "- When you create a repository on DagsHub, a remote MLflow server is automatically created and configured with the project. The repository's MLflow tracking server will be located at:\n",
        "\n",
        "  `https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow`\n",
        "\n",
        "<center><h3>In the session today, we will use DagsHub integration with MLflow and log experiment to a remote server by running only 3 simple commands!</h3></center>"
      ],
      "metadata": {
        "id": "qjFwt-Ysj4Tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ’» Hands-on Experience using MLflow"
      ],
      "metadata": {
        "id": "xfujaAmeGeHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demo the MLflow functionality, I choose to use [Eryk Lewinson's project](https://dagshub.com/eryk.lewinson/mario_vs_wario_v2), where he's training a model to classify images that hold Mario or Wario.\n",
        "\n",
        "To shorten the running time, I created a new branch that simplifies the pipeline and only holds the training stage with a small subset of the data.\n",
        "\n",
        "The train.py script has two main components:\n",
        "\n",
        "1.   Data loaders for the train, test, and validation set.\n",
        "\n",
        "2.   A small & simple NN model with four layers"
      ],
      "metadata": {
        "id": "7sBsk3NOGhJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ‘·â€â™€ï¸ Setup the project in Colab Runtime"
      ],
      "metadata": {
        "id": "6E4MGW5-FTE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DagsHub Configurations"
      ],
      "metadata": {
        "id": "wl78R8dPkRbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dagshub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwfAXvKpdxOT",
        "outputId": "3afdcef1-dc3e-4592-87bd-17a613e328aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dagshub\n",
            "  Downloading dagshub-0.3.27-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/232.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”\u001b[0m \u001b[32m204.8/232.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.10/dist-packages (from dagshub) (6.0.1)\n",
            "Collecting fusepy>=3 (from dagshub)\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from dagshub) (1.4.4)\n",
            "Requirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from dagshub) (8.1.7)\n",
            "Collecting httpx~=0.23.0 (from dagshub)\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=3.1.29 (from dagshub)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich~=13.1.0 (from dagshub)\n",
            "  Downloading rich-13.1.0-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dacite~=1.6.0 (from dagshub)\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting tenacity~=8.2.2 (from dagshub)\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Collecting gql[requests] (from dagshub)\n",
            "  Downloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from dagshub)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dagshub) (2.0.3)\n",
            "Collecting treelib~=1.6.4 (from dagshub)\n",
            "  Downloading treelib-1.6.4-py3-none-any.whl (18 kB)\n",
            "Collecting pathvalidate~=3.0.0 (from dagshub)\n",
            "  Downloading pathvalidate-3.0.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dagshub) (2.8.2)\n",
            "Collecting boto3 (from dagshub)\n",
            "  Downloading boto3-1.34.108-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from GitPython>=3.1.29->dagshub)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.23.0->dagshub) (2024.2.2)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx~=0.23.0->dagshub)\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx~=0.23.0->dagshub)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.23.0->dagshub) (1.3.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich~=13.1.0->dagshub)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich~=13.1.0->dagshub) (2.16.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from treelib~=1.6.4->dagshub) (1.16.0)\n",
            "Collecting botocore<1.35.0,>=1.34.108 (from boto3->dagshub)\n",
            "  Downloading botocore-1.34.108-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->dagshub)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->dagshub)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting graphql-core<3.3,>=3.2 (from gql[requests]->dagshub)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (1.9.4)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (3.7.1)\n",
            "Requirement already satisfied: requests<3,>=2.26 in /usr/local/lib/python3.10/dist-packages (from gql[requests]->dagshub) (2.31.0)\n",
            "Collecting requests-toolbelt<2,>=1.0.0 (from gql[requests]->dagshub)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dagshub) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dagshub) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->dagshub) (1.25.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql[requests]->dagshub) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.0->gql[requests]->dagshub) (1.2.1)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.108->boto3->dagshub) (2.0.7)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.0->dagshub)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.26->gql[requests]->dagshub) (3.3.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (4.11.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.0.5)\n",
            "Building wheels for collected packages: fusepy\n",
            "  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10487 sha256=7d5daa29a19c63f6ea8082e07aca335673197adc2c9ca7593e7e10c52a3a26dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
            "Successfully built fusepy\n",
            "Installing collected packages: rfc3986, fusepy, commonmark, treelib, tenacity, smmap, rich, pathvalidate, mypy-extensions, marshmallow, jmespath, h11, graphql-core, dacite, backoff, typing-inspect, requests-toolbelt, httpcore, gql, gitdb, botocore, s3transfer, httpx, GitPython, dataclasses-json, boto3, dagshub\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 8.3.0\n",
            "    Uninstalling tenacity-8.3.0:\n",
            "      Successfully uninstalled tenacity-8.3.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.1\n",
            "    Uninstalling rich-13.7.1:\n",
            "      Successfully uninstalled rich-13.7.1\n",
            "Successfully installed GitPython-3.1.43 backoff-2.2.1 boto3-1.34.108 botocore-1.34.108 commonmark-0.9.1 dacite-1.6.0 dagshub-0.3.27 dataclasses-json-0.6.6 fusepy-3.0.1 gitdb-4.0.11 gql-3.5.0 graphql-core-3.2.3 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 jmespath-1.0.1 marshmallow-3.21.2 mypy-extensions-1.0.0 pathvalidate-3.0.0 requests-toolbelt-1.0.0 rfc3986-1.5.0 rich-13.1.0 s3transfer-0.10.1 smmap-5.0.1 tenacity-8.2.3 treelib-1.6.4 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Enter the username of your DAGsHub account:\n",
        "DAGSHUB_USER_NAME = \"prodip1023\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the email for your DAGsHub account:\n",
        "DAGSHUB_EMAIL = \"Prodip#1989\" #@param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "ufslGlHVFYdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DAGSHUB_REPO_NAME=\"mario_vs_wariov1\"\n",
        "BRANCH=\"mlflow-101\""
      ],
      "metadata": {
        "id": "uw8Hr_-zFZAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Generate an Access Token, for improved account security**"
      ],
      "metadata": {
        "id": "ugEEh97mPfCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import getpass\n",
        "import datetime\n",
        "\n",
        "r = requests.post('https://dagshub.com/api/v1/user/tokens',\n",
        "                  json={\"name\": f\"colab-token-{datetime.datetime.now()}\"},\n",
        "                  auth=(DAGSHUB_USER_NAME, getpass.getpass('DAGsHub password:')))\n",
        "r.raise_for_status()\n",
        "DAGSHUB_TOKEN=r.json()['sha1']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9afz_9k6FqcI",
        "outputId": "8b1b359c-df32-4613-8b15-18f4db8dc223"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DAGsHub password:Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DAGSHUB_REPO_NAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pFHbmWKZKsuS",
        "outputId": "ae9c8f63-a30b-4ead-ac5f-1ba27945c0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mario_vs_wariov1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Migrate the repository under your user with [DagsHub API](https://dagshub.com/docs/api)**"
      ],
      "metadata": {
        "id": "Fg-Q1mtJF0bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "user_data = requests.get(\"https://dagshub.com/api/v1/user/\",auth=(DAGSHUB_USER_NAME,DAGSHUB_TOKEN))\n",
        "user = json.loads(user_data.text)\n",
        "\n",
        "p = {\n",
        "  \"clone_addr\": f\"https://dagshub.com/ShambhaviCodes/mario_vs_wario.git\",\n",
        "  \"repo_name\": f\"{DAGSHUB_REPO_NAME}\",\n",
        "  \"user_id\":user[\"id\"],\n",
        "  \"mirror\": True,\n",
        "  \"visibility\": \"public\",\n",
        "}\n",
        "\n",
        "r = requests.post(\"https://dagshub.com/api/v1/repos/migrate\", data=p, auth=(DAGSHUB_USER_NAME,DAGSHUB_TOKEN))\n",
        "if r.status_code == 201:\n",
        "  print(\"Migration succeeded\")\n",
        "else:\n",
        "  print(\"Migration faild with error:\\n\", r.text)"
      ],
      "metadata": {
        "id": "EoUs9aPUFtgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3e5bb7-3000-4a10-bc90-191c0ac0ae89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migration faild with error:\n",
            " {\"message\":\"repository already exists [uname: prodip1023, name: mario_vs_wariov1]\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## â¬ Clone the Project and Pull the data to Colab Runtime"
      ],
      "metadata": {
        "id": "MU7dNou0F9m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configure Git**"
      ],
      "metadata": {
        "id": "QQsYUtDwGE1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email {DAGSHUB_EMAIL}\n",
        "!git config --global user.name {DAGSHUB_USER_NAME}"
      ],
      "metadata": {
        "id": "NkYJ39OXF7WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone the Repository**"
      ],
      "metadata": {
        "id": "Rd02jjRRGGFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b {BRANCH} https://{DAGSHUB_USER_NAME}:{DAGSHUB_TOKEN}@dagshub.com/{DAGSHUB_USER_NAME}/{DAGSHUB_REPO_NAME}.git\n",
        "%cd {DAGSHUB_REPO_NAME}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og48wUBwGASF",
        "outputId": "52b194a8-0a5a-458e-e21e-9f617ace6c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mario_vs_wariov1'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 69 (delta 17), reused 69 (delta 17), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (69/69), 306.38 KiB | 1.31 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "/content/mario_vs_wariov1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install and Configure DVC**"
      ],
      "metadata": {
        "id": "TTjjspauGSh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install dvc>=2.8.1 --quiet\n",
        "\n",
        "# Import DVC package (relevant only when working in a Colab environment)\n",
        "import dvc\n",
        "\n",
        "# General DVC user configuration\n",
        "!dvc remote modify --local origin auth basic\n",
        "!dvc remote modify --local origin user {DAGSHUB_USER_NAME}\n",
        "!dvc remote modify --local origin password {DAGSHUB_TOKEN}\n",
        "\n",
        "!dvc pull -r origin >& dev_null\n",
        "\n",
        "# Make sure that all files were pulled\n",
        "!dvc pull -r origin >& dev_null"
      ],
      "metadata": {
        "id": "ZPiFDLLtGKLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2ee2be-a516-46ad-e581-65ae6a7db661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## â³ Install MLflow\n",
        "MLflow is installed using pip.\n",
        "\n",
        "*Note*: MLflow has several types of versions, each with different support.\n",
        "\n",
        "* Install MLflow\n",
        "\n",
        "  `pip install mlflow`\n",
        "\n",
        "* Install MLflow with the experimental MLflow Pipelines component\n",
        "\n",
        "  `pip install mlflow[pipelines]`\n",
        "\n",
        "* Install MLflow with extra ML libraries and 3rd-party tools\n",
        "\n",
        "  `pip install mlflow[extras]`\n",
        "\n",
        "* Install a lightweight version of MLflow\n",
        "    \n",
        "    `pip install mlflow-skinny`"
      ],
      "metadata": {
        "id": "d5DIqa7EGqsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow --quiet"
      ],
      "metadata": {
        "id": "3grGRw_ZGn1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKnHr0iBf34I",
        "outputId": "84bf5d21-db0c-4d38-f27e-e8bcff570171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 7s 246ms/step - loss: 0.7213 - accuracy: 0.5514 - val_loss: 0.7079 - val_accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.7062 - accuracy: 0.4393 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 141ms/step - loss: 0.6868 - accuracy: 0.5888 - val_loss: 0.6836 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 122ms/step - loss: 0.6895 - accuracy: 0.5981 - val_loss: 0.6769 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 126ms/step - loss: 0.6925 - accuracy: 0.5421 - val_loss: 0.6843 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 125ms/step - loss: 0.6828 - accuracy: 0.6355 - val_loss: 0.6751 - val_accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 137ms/step - loss: 0.6757 - accuracy: 0.5981 - val_loss: 0.6614 - val_accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 102ms/step - loss: 0.6654 - accuracy: 0.5981 - val_loss: 0.6214 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.6649 - accuracy: 0.5514 - val_loss: 0.6241 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.6474 - accuracy: 0.6075 - val_loss: 0.6614 - val_accuracy: 0.6000\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 0.7312 - accuracy: 0.4444\n",
            "Evaluating completed.\n",
            "Saving the model...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Log Experiments Locally"
      ],
      "metadata": {
        "id": "-anNKKYaGxuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Import MLflow\n"
      ],
      "metadata": {
        "id": "o1vQ19POG30n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# We will import mlflow to the train.py where we will later log our runs.\n",
        "import mlflow\n",
        "```"
      ],
      "metadata": {
        "id": "T6QZf0cpOE4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Create an Experiment & Get the Experiment ID\n",
        "\n",
        "There are two ways to create an experiment with MLflow :\n",
        "1. **CLI** (Command-Line Interface)\n",
        "\n",
        "  MLflow supports various functionalities from the [CLI](https://www.mlflow.org/docs/latest/cli.html). You can use the CLI to run projects, launch the Tracking UI, create and list experiments, and more.\n",
        "\n",
        "  To create a new experiment use:\n",
        "  ```\n",
        "  mlflow experiments create --experiment-name <experiment_name>\n",
        "  ```\n",
        "\n",
        "2. **Python API**\n",
        "    ```\n",
        "    mlflow.create_experiment(name)\n",
        "    ```\n",
        "\n",
        "**Note**: The process of creating an experiment should be separated from the project pipeline or main code because we don't need to create a new one every time we run it."
      ],
      "metadata": {
        "id": "rzE99ovrHF1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "import mlflow\n",
        "\n",
        "def get_experiment_id(name):\n",
        "    exp = mlflow.get_experiment_by_name(name)\n",
        "    if exp is None:\n",
        "      exp_id = mlflow.create_experiment(name)\n",
        "      return exp_id\n",
        "    return exp.experiment_id\n",
        "\n",
        "print(get_experiment_id(\"mario_wario\"))\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "TUrFUDJZY7m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/get_or_create_mlflow_experiment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXbaGC5CGtP4",
        "outputId": "66142bf6-0222-4bba-9fb1-705b730fafcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "841111797122009502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Allocate the run to the Experiment\n",
        "\n",
        "We start an MLflow run with the command :\n",
        "```\n",
        "with mlflow.start_run(experiment_id=<experiment id>):\n",
        "```\n",
        "We will copy paste this to our train.py with the Experiment ID that we obtained from our last code execution.\n",
        "\n",
        "***Note:*** The code that followes this lime needs to be indented to the `with` block"
      ],
      "metadata": {
        "id": "rUeAdt1TI_5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Log Information  \n",
        "\n",
        "We will start by importing MLflow into our notebook or a .py file. Then we can start using the manual logging commands to log parameters, metrics, artifacts, and general using the following methods:\n",
        "\n",
        "* **Parameters**:\n",
        "  * [Single parameter](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param): mlflow.log_param(*key, value*)\n",
        "  * [Multiple parameters](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_params): mlflow.log_params(*dict*)\n",
        "* **Metrics:**\n",
        "  * [Single metric](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric): mlflow.log_metric(*key, value*)\n",
        "  * [Multiple metrics](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metrics): mlflow.log_metrics(*dict*)\n",
        "* **Artifacts**:\n",
        "  * [Single artifact](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_artifact): mlflow.log_artifact(*local_path: str*)\n",
        "* **Text**:\n",
        "  * [Text](https://www.mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_text): mlflow.log_text(*string*,*local_path: str*)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "***Note***: MLflow has additional logging capabilities, to read more about them please refer to the [MLflow Tracking docs](https://www.mlflow.org/docs/latest/python_api/mlflow.html#module-mlflow)\n",
        "\n",
        "\n",
        "***Note***: All the mlflow code in this section should be under the `with mlflow.start_run(experiment_id=<experiment id>):` line from the previous section.\n",
        "\n",
        "```\n",
        "# Single parameter\n",
        "mlflow.log_param(\"img_size\", IMG_SIZE)\n",
        "\n",
        "# Multiple parameters\n",
        "mlflow.log_params({\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"learning_rate\": LR,\n",
        "    \"epochs\": EPOCHS\n",
        "})\n",
        "\n",
        "# Single metric\n",
        "mlflow.log_metric(\"test_set_loss\", test_loss)\n",
        "\n",
        "\n",
        "# Multiple metrics\n",
        "mlflow.log_metrics(\n",
        "    {\n",
        "        \"test_set_loss\": test_loss,\n",
        "        \"test_set_accuracy\": test_accuracy,\n",
        "    }\n",
        ")\n",
        "\n",
        "mlflow.log_artifact(MODELS_DIR)\n",
        "\n",
        "mlflow.log_text(\"Here you can add general inforamtion about the run\",\"run_info.txt\")\n",
        "```"
      ],
      "metadata": {
        "id": "4q_aHvrnIlv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Time to see the magic! ğŸ”"
      ],
      "metadata": {
        "id": "Fuui_bvgKmaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/{DAGSHUB_REPO_NAME}/src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4F11GuVIWIq",
        "outputId": "84ebb7b7-b3e1-4afb-d6d8-202f787ca0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "841111797122009502\n",
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 2s 114ms/step - loss: 0.6843 - accuracy: 0.5794 - val_loss: 0.6815 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.6751 - accuracy: 0.6075 - val_loss: 0.6643 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.6907 - accuracy: 0.5888 - val_loss: 0.6574 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.6755 - accuracy: 0.6262 - val_loss: 0.6573 - val_accuracy: 0.5600\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.6653 - accuracy: 0.6542 - val_loss: 0.6544 - val_accuracy: 0.7600\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.6464 - accuracy: 0.6916 - val_loss: 0.6405 - val_accuracy: 0.6400\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6014 - accuracy: 0.7103 - val_loss: 0.6103 - val_accuracy: 0.5600\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.5858 - accuracy: 0.7103 - val_loss: 0.5988 - val_accuracy: 0.7200\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 135ms/step - loss: 0.5932 - accuracy: 0.6262 - val_loss: 0.6547 - val_accuracy: 0.5600\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 84ms/step - loss: 0.5507 - accuracy: 0.6822 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6079 - accuracy: 0.6222\n",
            "Evaluating completed.\n",
            "Saving the model...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore the Files\n",
        "\n",
        "The information will be logged to the `mlruns` directory.\n",
        "\n",
        "In our example the directory will have the following structure:\n",
        "\n",
        "```\n",
        "mlruns\n",
        "â””â”€â”€ <experiment ID>\n",
        "    â”œâ”€â”€ <Run Hash>\n",
        "    â”‚   â”œâ”€â”€ artifacts\n",
        "    â”‚   â”‚   â”œâ”€â”€ models\n",
        "    â”‚   â”‚   â””â”€â”€ run_info.txt\n",
        "    â”‚   â”œâ”€â”€ meta.yaml\n",
        "    â”‚   â”œâ”€â”€ metrics\n",
        "    â”‚   â”‚   â”œâ”€â”€ test_set_accuracy\n",
        "    â”‚   â”‚   â””â”€â”€ test_set_loss\n",
        "    â”‚   â”œâ”€â”€ params\n",
        "    â”‚   â”‚   â”œâ”€â”€ epochs\n",
        "    â”‚   â”‚   â”œâ”€â”€ img_size\n",
        "    â”‚   â”‚   â””â”€â”€ learning_rate\n",
        "    â”‚   â””â”€â”€ tags\n",
        "    â”‚       â”œâ”€â”€ mlflow.source.git.commit\n",
        "    â”‚       â”œâ”€â”€ mlflow.source.name\n",
        "    â”‚       â”œâ”€â”€ mlflow.source.type\n",
        "    â”‚       â””â”€â”€ mlflow.user\n",
        "    â””â”€â”€ meta.yaml\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "O_cxp1fcK-7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## â˜ï¸ Log Experiments to a Remote Tracking Server\n",
        "\n",
        "To avoide the long process of setting up a remote server,  we will use DagsHub integration with MLflow.\n",
        "\n",
        "When you create a repository on DagsHub, a remote MLflow server is automatically created and configured with the project. The repository's MLflow tracking server will be located at:\n",
        "\n",
        "`https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow`\n",
        "\n",
        "To set the remote server with you machine you need to:\n",
        "1. **Set DagsHub as the remote URI -**\n",
        "  * `mlflow.set_tracking_uri(\"https://dagshub.com/<DagsHub-user-name>/<repository-name>.mlflow\")`\n",
        "2. **Set-up your credentials as OS variables**:\n",
        "  * `export MLFLOW_TRACKING_USERNAME=<DagsHub-user-name/token>`\n",
        "  * `export MLFLOW_TRACKING_PASSWORD=<password>`\n",
        "\n",
        "**Congratulations**, you are ready to start logging experiments."
      ],
      "metadata": {
        "id": "OrYrefNqLLzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Set up environment variables"
      ],
      "metadata": {
        "id": "R7KtpI0tNyNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# TODO: Explain that it's recommended to define this in the code because it's project specific\n",
        "os.environ['MLFLOW_TRACKING_URI']=f\"https://dagshub.com/{DAGSHUB_USER_NAME}/mario_vs_wariov1.mlflow\"\n",
        "\n",
        "# Recommended to define as environment variables\n",
        "os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USER_NAME\n",
        "os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN"
      ],
      "metadata": {
        "id": "CSznfaCFNmfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Create a new experiment on the remote server\n",
        "\n",
        "We will modify get_or_create_mlflow_experiment.py, and set the tracking URI\n",
        "\n",
        "```\n",
        "import mlflow\n",
        "import os\n",
        "\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "\n",
        "def get_experiment_id(name):\n",
        "    exp = mlflow.get_experiment_by_name(name)\n",
        "    if exp is None:\n",
        "      exp_id = mlflow.create_experiment(name)\n",
        "      return exp_id\n",
        "    return exp.experiment_id\n",
        "\n",
        "print(get_experiment_id(\"mario_wario\"))\n",
        "```"
      ],
      "metadata": {
        "id": "hwYgCo93NYoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/{DAGSHUB_REPO_NAME}/src/get_or_create_mlflow_experiment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19MUlYxLpKGx",
        "outputId": "211af710-1b14-46f4-d3f3-9825e93487c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Modify the train.py script\n",
        "\n",
        "We will modify train.py, and set the tracking URI and set the new experiment id\n"
      ],
      "metadata": {
        "id": "9rcECrp3hrLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# To be added to the top of train.py\n",
        "\n",
        "import os\n",
        "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
        "# Recommended way:\n",
        "# mlflow.set_tracking_uri(\"https://dagshub.com/{user name}/{repo name}.mlflow\")\n",
        "\n",
        "# To be added in lime 93\n",
        "with mlflow.start_run(experiment_id=<experiment id>):\n",
        "```"
      ],
      "metadata": {
        "id": "X5Qe0SHgN50N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lN_Gpykkgqx",
        "outputId": "1b50dbdf-8290-4a72-c42c-94b055d024e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/05/19 02:09:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
            "2024/05/19 02:09:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/05/19 02:09:21 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
            "2024/05/19 02:09:21 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.6846 - accuracy: 0.5514"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 4s 667ms/step - loss: 0.6846 - accuracy: 0.5514 - val_loss: 0.6763 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 2s 631ms/step - loss: 0.6943 - accuracy: 0.6075 - val_loss: 0.6734 - val_accuracy: 0.6800\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 2s 700ms/step - loss: 0.6849 - accuracy: 0.5607 - val_loss: 0.6661 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.6881 - accuracy: 0.5981 - val_loss: 0.6712 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 669ms/step - loss: 0.6739 - accuracy: 0.6355 - val_loss: 0.6705 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 0.6702 - accuracy: 0.6355 - val_loss: 0.6546 - val_accuracy: 0.6000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 745ms/step - loss: 0.6719 - accuracy: 0.6075 - val_loss: 0.6414 - val_accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 2s 640ms/step - loss: 0.6460 - accuracy: 0.6542 - val_loss: 0.6037 - val_accuracy: 0.7600\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 607ms/step - loss: 0.6469 - accuracy: 0.6355 - val_loss: 0.5937 - val_accuracy: 0.5600\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 2s 662ms/step - loss: 0.5858 - accuracy: 0.6542 - val_loss: 0.5267 - val_accuracy: 0.8800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/05/19 02:09:44 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
            "2024/05/19 02:09:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "2024/05/19 02:09:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5684 - accuracy: 0.6667\n",
            "Evaluating completed.\n",
            "Saving the model...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Logging & visualizing the runs on remote server"
      ],
      "metadata": {
        "id": "8SBptQ5-zK-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "display(IPython.display.IFrame(f\"https://dagshub.com/{DAGSHUB_USER_NAME}/mario_vs_wariov1/experiments/#/\",'100%',600))"
      ],
      "metadata": {
        "id": "UtbLjJKSzubh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "9e23d2b5-5c24-49c2-d3a6-24e52f6b8af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7db61edb51b0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600\"\n",
              "            src=\"https://dagshub.com/paulbindass/mario_vs_wariov1/experiments/#/\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Re-running the code to see the logs"
      ],
      "metadata": {
        "id": "jbEkavuGzmzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/{DAGSHUB_REPO_NAME}/src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpx81y7-N9i3",
        "outputId": "669166eb-b42b-47be-9b3c-b33ac1fd78ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 142ms/step - loss: 0.8121 - accuracy: 0.5047 - val_loss: 0.6834 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 108ms/step - loss: 0.6779 - accuracy: 0.5794 - val_loss: 0.6816 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.6806 - accuracy: 0.5701 - val_loss: 0.6815 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.6624 - accuracy: 0.5981 - val_loss: 0.6688 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.6744 - accuracy: 0.5514 - val_loss: 0.6592 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.6745 - accuracy: 0.5888 - val_loss: 0.6523 - val_accuracy: 0.7600\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.6780 - accuracy: 0.5607 - val_loss: 0.6513 - val_accuracy: 0.5600\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.6551 - accuracy: 0.6636 - val_loss: 0.6369 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.6453 - accuracy: 0.6355 - val_loss: 0.5990 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.6115 - accuracy: 0.6636 - val_loss: 0.5366 - val_accuracy: 0.8400\n",
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5808 - accuracy: 0.6000\n",
            "Evaluating completed.\n",
            "Saving the model...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸš– Logging all your information to a run with an Autologger!\n"
      ],
      "metadata": {
        "id": "d4Y9YshflFLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If you are a forgetful human logger like me who always forgets to log something to the TensorBoard or the outputs, you will probably appreciate this feature the most!\n",
        "\n",
        "Automatic logging allows you to log metrics, parameters, and models without the need for explicit log statements. MLFlow Autologger supports the following libraries :\n",
        "\n",
        "1. Scikit-learn\n",
        "2. TensorFlow and Keras\n",
        "3. Gluon\n",
        "4. XGBoost\n",
        "5. LightGBM\n",
        "6. Statsmodels\n",
        "7. Spark\n",
        "8. Fastai\n",
        "9. Pytorch\n",
        "\n",
        "While you can use `mlflow.autolog()` to enable logging for all the above supported libraries, alternatively you can use library-specific autolog calls for each library, letâ€™s use the specific autolog call for tensorflow :\n"
      ],
      "metadata": {
        "id": "eV5rLMFT0Jx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add ```mlflow.tensorflow.autolog()``` right above the call ```with mlflow.start_run():``` and re-run your code to see the logged metrics and artifacts with the autologger."
      ],
      "metadata": {
        "id": "km10q-b90Rid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/{DAGSHUB_REPO_NAME}/src/train.py"
      ],
      "metadata": {
        "id": "HUW257oH2w35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ed8366-8777-4d01-daf4-5d126d98ad1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 107 images belonging to 2 classes.\n",
            "Found 25 images belonging to 2 classes.\n",
            "Found 45 images belonging to 2 classes.\n",
            "Training the model...\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 236ms/step - loss: 0.7090 - accuracy: 0.5607 - val_loss: 0.6715 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 95ms/step - loss: 0.6697 - accuracy: 0.5701 - val_loss: 0.6791 - val_accuracy: 0.6000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.6753 - accuracy: 0.6168 - val_loss: 0.6722 - val_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.6882 - accuracy: 0.5701 - val_loss: 0.6672 - val_accuracy: 0.6000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.6595 - accuracy: 0.6542 - val_loss: 0.6478 - val_accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 116ms/step - loss: 0.6655 - accuracy: 0.5981 - val_loss: 0.6241 - val_accuracy: 0.8400\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 91ms/step - loss: 0.6476 - accuracy: 0.6262 - val_loss: 0.6173 - val_accuracy: 0.7600\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 0.6212 - accuracy: 0.6636 - val_loss: 0.6104 - val_accuracy: 0.5600\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 93ms/step - loss: 0.5966 - accuracy: 0.6822 - val_loss: 0.7369 - val_accuracy: 0.4800\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 92ms/step - loss: 0.6089 - accuracy: 0.7009 - val_loss: 0.6559 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/09/20 16:51:06 WARNING mlflow.utils.requirements_utils: Found tensorflow version (2.8.2+zzzcolab20220719082949) contains a local version label (+zzzcolab20220719082949). MLflow logged a pip requirement for this package as 'tensorflow==2.8.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2022/09/20 16:51:13 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpdq3vrdlj/model, flavor: keras), fall back to return ['tensorflow==2.8.2', 'keras==2.8.0']. Set logging level to DEBUG to see the full traceback.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed.\n",
            "Evaluating the model...\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.5443 - accuracy: 0.6222\n",
            "Evaluating completed.\n",
            "Saving the model...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the project"
      ],
      "metadata": {
        "id": "R9Jt9KhTdBXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -a -m \"added mlflow logging\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq5XWSDYc36X",
        "outputId": "da192694-ab67-42ef-be6e-12a9500f2c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mlflow-101 ac323fe] added mlflow logging\n",
            " 2 files changed, 27 insertions(+), 17 deletions(-)\n",
            "error: src refspec main does not match any\n",
            "error: failed to push some refs to 'https://dagshub.com/paulbindass/mario_vs_wariov1.git'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull --rebase origin main\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtUblVQGoe-w",
        "outputId": "1f6f79af-ab70-411a-c54a-453c98a17e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://dagshub.com/paulbindass/mario_vs_wariov1\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Rebasing (5/10)\rAuto-merging data/processed.dvc\n",
            "CONFLICT (content): Merge conflict in data/processed.dvc\n",
            "error: could not apply 29e5a54... Updated the resized dataset\n",
            "hint: Resolve all conflicts manually, mark them as resolved with\n",
            "hint: \"git add/rm <conflicted_files>\", then run \"git rebase --continue\".\n",
            "hint: You can instead skip this commit: run \"git rebase --skip\".\n",
            "hint: To abort and get back to the state before \"git rebase\", run \"git rebase --abort\".\n",
            "Could not apply 29e5a54... Updated the resized dataset\n",
            "error: src refspec main does not match any\n",
            "error: failed to push some refs to 'https://dagshub.com/paulbindass/mario_vs_wariov1.git'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¥· And you are an MLflow Tracking Ninja!\n",
        "\n",
        "\n",
        "**Behold! One more tutorial to go till you become an MLflow Ninja!**\n",
        "\n",
        "I hope that you are comfortable with the MLflow tool now and would consider it as your go-to ML Workflow Management tool just like me! If you have doubts, you run into errors or you would like to share your experience, please feel free to join our Discord and join us as we build our community stronger each day!\n",
        "\n",
        "See you on 27th September where my MLflow pro friend Yono will show you how to [Register ML Models and Deploy them with Mlflow](https://www.linkedin.com/events/mlflowcrashcourse-part26975758317688111104/comments/)\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1ajZSBD1LzOyNn3uIFL5l422JmDBiZmBC\" height=\"\"/></center>"
      ],
      "metadata": {
        "id": "dIO-Angr0vSJ"
      }
    }
  ]
}